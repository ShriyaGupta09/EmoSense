{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85b984cb-cff3-4a1a-8d67-9a29a52462f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2066c46d-27dc-46f2-a0d8-227adeacb5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'images/train'\n",
    "TEST_DIR = 'images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28ecbddd-1286-4742-a961-d1839fbdde1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir, label)):\n",
    "            image_paths.append(os.path.join(dir, label, imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"completed\")\n",
    "    return image_paths, labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3efb4f0-07b7-41dd-9cf1-92d35a941d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "484806be-2547-4ae8-8b02-857a475037fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                image    label\n",
      "0            images/train\\angry\\0.jpg    angry\n",
      "1            images/train\\angry\\1.jpg    angry\n",
      "2           images/train\\angry\\10.jpg    angry\n",
      "3        images/train\\angry\\10002.jpg    angry\n",
      "4        images/train\\angry\\10016.jpg    angry\n",
      "...                               ...      ...\n",
      "17763  images/train\\neutral\\23313.jpg  neutral\n",
      "17764  images/train\\neutral\\23317.jpg  neutral\n",
      "17765   images/train\\neutral\\2334.jpg  neutral\n",
      "17766  images/train\\neutral\\23344.jpg  neutral\n",
      "17767  images/train\\neutral\\23356.jpg  neutral\n",
      "\n",
      "[17768 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    " print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8523036-bed3-491d-8ee9-2bb551b16bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], train['label'] = createdataframe(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b182e40c-09db-412f-854f-582df9d3a37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                image\n",
      "0            images/train\\angry\\0.jpg\n",
      "1            images/train\\angry\\1.jpg\n",
      "2           images/train\\angry\\10.jpg\n",
      "3        images/train\\angry\\10002.jpg\n",
      "4        images/train\\angry\\10016.jpg\n",
      "...                               ...\n",
      "17763  images/train\\neutral\\23313.jpg\n",
      "17764  images/train\\neutral\\23317.jpg\n",
      "17765   images/train\\neutral\\2334.jpg\n",
      "17766  images/train\\neutral\\23344.jpg\n",
      "17767  images/train\\neutral\\23356.jpg\n",
      "\n",
      "[17768 rows x 1 columns]\n",
      "0              images/train\\angry\\0.jpg\n",
      "1              images/train\\angry\\1.jpg\n",
      "2             images/train\\angry\\10.jpg\n",
      "3          images/train\\angry\\10002.jpg\n",
      "4          images/train\\angry\\10016.jpg\n",
      "                      ...              \n",
      "17763    images/train\\neutral\\23313.jpg\n",
      "17764    images/train\\neutral\\23317.jpg\n",
      "17765     images/train\\neutral\\2334.jpg\n",
      "17766    images/train\\neutral\\23344.jpg\n",
      "17767    images/train\\neutral\\23356.jpg\n",
      "Name: image, Length: 17768, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test)\n",
    "print(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83d048c7-1d74-4732-8b94-5c4cd2220fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from keras_preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c29faff4-e73c-41ce-8f98-c4a119c622b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image, grayscale = True)\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features),48,48,1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0243e307-36bb-4288-84a7-e1fa6377ba22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246a838efe044f60acd980c992aaf047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17768 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `load_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(images)\u001b[0m\n\u001b[0;32m      2\u001b[0m features \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m tqdm(images):\n\u001b[1;32m----> 4\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrayscale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img)\n\u001b[0;32m      6\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(img)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_preprocessing\\image\\utils.py:111\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    109\u001b[0m     color_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrayscale\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pil_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not import PIL.Image. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    112\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe use of `load_img` requires PIL.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    114\u001b[0m     img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import PIL.Image. The use of `load_img` requires PIL."
     ]
    }
   ],
   "source": [
    "train_features = extract_features(train['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac2b25-ff6a-4672-8efb-1d7cc87d19ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
